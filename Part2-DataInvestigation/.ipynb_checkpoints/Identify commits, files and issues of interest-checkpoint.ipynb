{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04aac096",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98639107",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import jsonpickle\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ac0cfc",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d92b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FOLDER = \"./../data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a8404e",
   "metadata": {},
   "outputs": [],
   "source": [
    "COMMIT_DATA_FILE_NAME = \"commit_data_\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "996e9122",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f24f36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "REPO_NAME_TO_ID = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aaa36f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {}\n",
    "for file in os.listdir(DATA_FOLDER):\n",
    "        if COMMIT_DATA_FILE_NAME in file:\n",
    "            with open(os.path.join(DATA_FOLDER, file), \"r\") as f_in:\n",
    "                for line in f_in:\n",
    "                    repo_data = jsonpickle.decode(line)\n",
    "                    repo_name = list(repo_data.keys())[0]\n",
    "                    repo_id = int(file.replace(COMMIT_DATA_FILE_NAME, \"\").replace(\".json\", \"\"))\n",
    "                    data.update(repo_data)\n",
    "                    REPO_NAME_TO_ID[repo_name] = repo_id\n",
    "                    #\n",
    "                    print(repo_name, \"==>\", file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b506203",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef213c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_distribution(data, title, buckets=100, x_min=None, x_max=None):\n",
    "    if x_min is not None:\n",
    "        data = [v for v in data if v >= x_min]   \n",
    "    if x_max is not None:\n",
    "        data = [v for v in data if v <= x_max]   \n",
    "    plt.hist(data, buckets)\n",
    "    plt.title(title)\n",
    "    if x_min is not None and x_max is not None:\n",
    "        plt.xlim(x_min, x_max)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdab725c",
   "metadata": {},
   "source": [
    "## Basic data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f85895",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_commit_cnt = 0\n",
    "for repo in data:\n",
    "    if repo in [\"gatsbyjs/gatsby\", \"scikit-learn/scikit-learn\", \"elastic/elasticsearch\"]:\n",
    "        continue\n",
    "    print(f\"{repo} number of commits: {len(data[repo]['commits'])}\")\n",
    "    total_commit_cnt = total_commit_cnt + len(data[repo]['commits'])\n",
    "print(\"Total commit cnt:\", total_commit_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd98b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "for repo in data:\n",
    "    repo_commits = data[repo][\"commits\"]\n",
    "    print(f\"Repository: {repo} \\t==> {len(repo_commits)}\")\n",
    "    commit_stat_data = {\n",
    "        \"files_per_commit\": []\n",
    "    }\n",
    "    #\n",
    "    for commit in repo_commits:\n",
    "        files = commit[\"files\"]\n",
    "        commit_stat_data[\"files_per_commit\"].append(len(files))\n",
    "    #\n",
    "    avg_files_per_commit = sum(commit_stat_data['files_per_commit'])/len(commit_stat_data['files_per_commit'])\n",
    "    #\n",
    "    fc_plus = [fc for fc in commit_stat_data['files_per_commit'] if fc > 0]\n",
    "    avg_files_per_commit_with_file = sum(fc_plus) / len(fc_plus)\n",
    "    #\n",
    "    cnt_commit_without_files = len([1 for fc in commit_stat_data['files_per_commit'] if fc == 0])\n",
    "    #\n",
    "    print(f\"\\t Avg files per commit: {avg_files_per_commit}\")\n",
    "    print(f\"\\t Avg files per commit with files: {avg_files_per_commit_with_file}\")\n",
    "    print(f\"\\t Cnt commit without file: {cnt_commit_without_files} => {round(100 * cnt_commit_without_files/len(repo_commits), 2)}%\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "279942f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for repo in data:\n",
    "    data[repo][\"fc_plus_commits\"] = [c for c in data[repo][\"commits\"] if len(c[\"files\"]) > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2daf1fa1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for repo in data:\n",
    "    print(f\"Repository: {repo} \\t==> {len(data[repo]['fc_plus_commits'])}\")\n",
    "    #\n",
    "    commit_stat_data = {\n",
    "        \"changes\": [],\n",
    "        \"add\": [],\n",
    "        \"del\": []\n",
    "    }\n",
    "    #\n",
    "    commit_file_stat_data = {\n",
    "        \"changes\": [],\n",
    "        \"add\": [],\n",
    "        \"del\": []\n",
    "    }\n",
    "    #\n",
    "    for commit in data[repo][\"fc_plus_commits\"]:\n",
    "        change_cnt = 0\n",
    "        add_cnt = 0\n",
    "        del_cnt = 0\n",
    "        for file in commit[\"files\"]:\n",
    "            commit_file_stat_data[\"changes\"].append(file[\"change_cnt\"])\n",
    "            commit_file_stat_data[\"add\"].append(file[\"add_cnt\"])\n",
    "            commit_file_stat_data[\"del\"].append(file[\"del_cnt\"])\n",
    "            #\n",
    "            change_cnt = change_cnt + file[\"change_cnt\"]\n",
    "            add_cnt = add_cnt + file[\"add_cnt\"]\n",
    "            del_cnt = del_cnt + file[\"del_cnt\"]\n",
    "        commit_stat_data[\"changes\"].append(change_cnt)\n",
    "        commit_stat_data[\"add\"].append(add_cnt)\n",
    "        commit_stat_data[\"del\"].append(del_cnt)\n",
    "    #\n",
    "    print(f\"\\t Avg changes per commit: {sum(commit_stat_data['changes']) / len(commit_stat_data['changes'])}\")\n",
    "    print(f\"\\t Avg adds per commit: {sum(commit_stat_data['add']) / len(commit_stat_data['add'])}\")\n",
    "    print(f\"\\t Avg dels per commit: {sum(commit_stat_data['del']) / len(commit_stat_data['del'])}\")\n",
    "    print()\n",
    "    print(f\"\\t Avg changes per file: {sum(commit_file_stat_data['changes']) / len(commit_file_stat_data['changes'])}\")\n",
    "    print(f\"\\t Avg adds per file: {sum(commit_file_stat_data['add']) / len(commit_file_stat_data['add'])}\")\n",
    "    print(f\"\\t Avg dels per file: {sum(commit_file_stat_data['del']) / len(commit_file_stat_data['del'])}\")\n",
    "    print()\n",
    "    MIN_VALUE = 0\n",
    "    MAX_VALUE = 250\n",
    "    plot_distribution(commit_stat_data['changes'], \"Changes per commit\", x_min=MIN_VALUE, x_max=MAX_VALUE)\n",
    "    plot_distribution(commit_stat_data['add'], \"Add per commit\", x_min=MIN_VALUE, x_max=MAX_VALUE)\n",
    "    plot_distribution(commit_stat_data['del'], \"Del per commit\", x_min=MIN_VALUE, x_max=MAX_VALUE)\n",
    "    plot_distribution(commit_file_stat_data['changes'], \"Changes per file\", x_min=MIN_VALUE, x_max=MAX_VALUE)\n",
    "    plot_distribution(commit_file_stat_data['add'], \"Add per file\", x_min=MIN_VALUE, x_max=MAX_VALUE)\n",
    "    plot_distribution(commit_file_stat_data['del'], \"Del per file\", x_min=MIN_VALUE, x_max=MAX_VALUE)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfbe0cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for repo in data:\n",
    "    print(f\"Repository: {repo} \\t==> {len(data[repo]['fc_plus_commits'])}\")\n",
    "    #\n",
    "    per_file_data = {}\n",
    "    #\n",
    "    for commit in data[repo][\"fc_plus_commits\"]:\n",
    "        for file in commit[\"files\"]:\n",
    "            file_name = file[\"name\"]\n",
    "            if file_name not in per_file_data:\n",
    "                per_file_data[file_name] = []\n",
    "            per_file_data[file_name].append(commit)\n",
    "    #\n",
    "    data[repo][\"per_file\"] = per_file_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f750666",
   "metadata": {},
   "outputs": [],
   "source": [
    "for repo in data:\n",
    "    print(f\"Repository: {repo} \\t==> {len(data[repo]['per_file'])} unique files\")\n",
    "    avg_commits_per_file = 0\n",
    "    for file in data[repo]['per_file']:\n",
    "        commits_per_file = len(data[repo]['per_file'][file])\n",
    "        avg_commits_per_file = avg_commits_per_file + commits_per_file\n",
    "    avg_commits_per_file = avg_commits_per_file / len(data[repo]['per_file'])\n",
    "    print(f\"\\t Avg commits per file: {avg_commits_per_file}\")\n",
    "    print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e67d97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ISSUE_REF_REGEX = r\"(?:#|\\/issues\\/|\\/pull\\/)(\\d+)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17dc0ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_strings = [\n",
    "    \"This is a issue: #123 , #124 and https://github.com/yt-dlp/yt-dlp/issues/4635#issuecomment-1235384480\",\n",
    "    \"cb0a719f67136e31b68d6f6e794fee10b256bf21\",\n",
    "    \"PR-URL: https://github.com/nodejs/node/pull/42796\"\n",
    "]\n",
    "for dummy in dummy_strings:\n",
    "    res = re.findall(ISSUE_REF_REGEX, dummy)\n",
    "    print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3edb435",
   "metadata": {},
   "outputs": [],
   "source": [
    "for repo in data:\n",
    "    print(f\"Repository: {repo} \\t==> {len(data[repo]['fc_plus_commits'])}\")\n",
    "    #\n",
    "    cnt = 0\n",
    "    for i, commit in enumerate(data[repo][\"fc_plus_commits\"]):\n",
    "        refs = re.findall(ISSUE_REF_REGEX, commit[\"msg\"])\n",
    "        commit[\"has_refs\"] = len(refs) > 0\n",
    "        commit[\"refs\"] = set(refs)\n",
    "        if commit[\"has_refs\"]:\n",
    "            cnt = cnt + 1\n",
    "    print(f\"\\tCommit with ref: {cnt}\")\n",
    "    print()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e055e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "files_of_interest = {}\n",
    "\n",
    "for repo in data:\n",
    "    print(f\"Repository: {repo} \\t==> {len(data[repo]['per_file'])} unique files\")\n",
    "    files_of_interest[repo] = {}\n",
    "    files_with_all_refs = 0\n",
    "    files_with_all_refs_multiple_commits = 0\n",
    "    issues_of_interest = set()\n",
    "    for file in data[repo]['per_file']:\n",
    "        has_ref_cnt = 0\n",
    "        for commit in data[repo]['per_file'][file]:\n",
    "            if commit[\"has_refs\"]:\n",
    "                has_ref_cnt = has_ref_cnt + 1\n",
    "        if has_ref_cnt == len(data[repo]['per_file'][file]):\n",
    "            files_with_all_refs = files_with_all_refs + 1\n",
    "            #\n",
    "            if has_ref_cnt > 1:\n",
    "                files_with_all_refs_multiple_commits = files_with_all_refs_multiple_commits + 1\n",
    "            #\n",
    "            for commit in data[repo]['per_file'][file]:\n",
    "                for ref in commit[\"refs\"]:\n",
    "                    issues_of_interest.add(ref)\n",
    "            #\n",
    "            files_of_interest[repo][file] = data[repo]['per_file'][file]\n",
    "    #\n",
    "    repo_files_of_intrest = {}\n",
    "    repo_files_of_intrest[repo] = files_of_interest[repo]\n",
    "    #\n",
    "    encoded = jsonpickle.encode(repo_files_of_intrest)\n",
    "    repoId = REPO_NAME_TO_ID[repo]\n",
    "    with open(os.path.join(DATA_FOLDER, f\"files_of_interest_{repoId}.json\"), \"w\") as f_out:\n",
    "        f_out.write(encoded)\n",
    "    print(f\"\\Files with all ref: {files_with_all_refs}\")\n",
    "    print(f\"\\Files with all ref and multiple commits: {files_with_all_refs_multiple_commits}\")\n",
    "    print(f\"\\Issues of interest: {len(issues_of_interest)}\")\n",
    "    print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f081da21",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded = jsonpickle.encode(files_of_interest)\n",
    "with open(os.path.join(DATA_FOLDER, \"files_of_interest.json\"), \"w\") as f_out:\n",
    "    f_out.write(encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22afb5e6",
   "metadata": {},
   "source": [
    "## Separate issues of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe41bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ISSUE_DATA_FILE_NAME = \"issue-data.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef35262e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(DATA_FOLDER, ISSUE_DATA_FILE_NAME), \"r\") as f_in:\n",
    "    for line in f_in:\n",
    "        issue_data = jsonpickle.decode(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf58af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_issue_cnt = 0\n",
    "for repo in issue_data:\n",
    "    print(repo[\"name\"], \"\\t==>\", len(repo[\"issues\"]))\n",
    "    if repo[\"name\"] in [\"gatsbyjs/gatsby\", \"scikit-learn/scikit-learn\", \"elastic/elasticsearch\"]:\n",
    "        continue\n",
    "    total_issue_cnt = total_issue_cnt + len(repo[\"issues\"])\n",
    "print(f\"Total issue count: {total_issue_cnt}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2a5285",
   "metadata": {},
   "outputs": [],
   "source": [
    "issues_of_interest = {}\n",
    "for repo in files_of_interest:\n",
    "    issues_of_interest[repo] = {}\n",
    "    for file in files_of_interest[repo]:\n",
    "        for commit in files_of_interest[repo][file]:\n",
    "            for ref in commit[\"refs\"]:\n",
    "                ref = int(ref)\n",
    "                if ref not in issues_of_interest[repo]:\n",
    "                    issues_of_interest[repo][ref] = None\n",
    "#\n",
    "for repo in issue_data:\n",
    "    repo_name = repo[\"name\"]\n",
    "    if repo_name in issues_of_interest:\n",
    "        for issue in repo[\"issues\"]:\n",
    "            nmr = issue[\"number\"]\n",
    "            if nmr in issues_of_interest[repo_name]:\n",
    "                issues_of_interest[repo_name][nmr] = issue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ea4c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "ISSUE_OF_INTEREST_THRESHOLD = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9544864",
   "metadata": {},
   "outputs": [],
   "source": [
    "for repo in issues_of_interest:\n",
    "    not_found_cnt = 0\n",
    "    for nmr in issues_of_interest[repo]:\n",
    "        if issues_of_interest[repo][nmr] is None:\n",
    "            not_found_cnt = not_found_cnt + 1\n",
    "    #\n",
    "    print(repo, \"\\t==>\", f\"Number of issues not found: {not_found_cnt}/{len(issues_of_interest[repo])}\")   \n",
    "    #\n",
    "    threshold = not_found_cnt/len(issues_of_interest[repo])\n",
    "    #\n",
    "    if 1.0 - threshold > ISSUE_OF_INTEREST_THRESHOLD:\n",
    "        repo_issues_of_interest = {}\n",
    "        repo_issues_of_interest[repo] = issues_of_interest[repo]\n",
    "        #\n",
    "        encoded = jsonpickle.encode(repo_issues_of_interest)\n",
    "        #\n",
    "        repoId = REPO_NAME_TO_ID[repo]\n",
    "        with open(os.path.join(DATA_FOLDER, f\"issues_of_interest_{repoId}.json\"), \"w\") as f_out:\n",
    "            f_out.write(encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ae1abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded = jsonpickle.encode(issues_of_interest)\n",
    "#\n",
    "with open(os.path.join(DATA_FOLDER, \"issues_of_interest.json\"), \"w\") as f_out:\n",
    "    f_out.write(encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e11472",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
